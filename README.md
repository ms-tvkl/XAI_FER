# Explainable AI for Facial Expression Recognition 

This repository explores explainability methods applied to facial expression recognition models, focusing on understanding how and why predictions are made.
- Global_explanations_FER.ipynb
Demonstrates explainability techniques that summarize model behavior across many examples.
Examples: feature importance, class-level saliency maps, aggregated explanations.

- Local_explanation_FER.ipynb
Focuses on the explanation of individual predictions to help debug and understand specific decisions.
Examples: LIME, SHAP explanations on single FER predictions.
